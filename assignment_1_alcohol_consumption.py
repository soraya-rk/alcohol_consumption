# -*- coding: utf-8 -*-
"""Assignment 1 - Alcohol Consumption.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aAvhgTKmF4W47wq-_12G5-l5NC7-4F2p

**Tujuan**: Memprediksi variabel Walc (weekly alcohol consumption) dengan 4 model: linear regresi single input, linear regresi multiple input, DNN single input, dan DNN multiple input.

Data set yang digunakan: Student Alcohol Consumption (https://www.kaggle.com/uciml/student-alcohol-consumption)

---------------------------------------------------------

# Preparation
"""

# Import Libraries

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import io

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers.experimental import preprocessing

# Agar lebih muda dilihat, numpy disederhanakan menjadi 3 angka di belakang koma
np.set_printoptions(precision=3, suppress=True)

"""# Upload Data"""

# COpy URL sumber data
url = 'https://raw.githubusercontent.com/soraya-rk/alcohol_consumption/main/student-por.csv'

# membuat data frame dari URL CSV yang dicopy
df_por = pd.read_csv(url)

# Melihat struktur data df_por
df_por.head()

"""# Encoding The Data

Banyak data di df_por yang masih berupa data categorical, seperti sex yang berisi value M atau F. Encoding akan merubah kolom data tersebut menjadi sex_M dan sex_F yang akan berisi value 1 atau 0.
"""

# Pilih kolom mana yang merupakan data kategorikal dan harus diubah
col_select = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic' ]

# Eksekusi proses encoding data
enc_por = pd.get_dummies(df_por, columns=col_select, prefix=col_select)

# Cek hasil encoding
enc_por.head()

"""# Train the Data

Data df_por memiliki 649 row. Untuk membangun model prediksi menggunakan regresi dan Deep Neural Network (DNN), kita akan membagi data tersebut
80% untuk train, 20% untuk test.
"""

# Pisahkan Train & Test
train_por = enc_por.sample(frac=0.8, random_state=0)
test_por = enc_por.sample(frac=0.2, random_state=0)

"""Value yang akan kita prediksi adalah Walc (weekly alcohol consumption), sehingga Walc harus kita pisahkan sebagai labels."""

# Split features dari labels (Walc)

train_features = train_por.copy()
test_features = test_por.copy()

train_labels_Walc = train_features.pop('Walc')
test_labels_Walc = test_features.pop('Walc')

"""# Normalization
Mari kita lihat statistik deskriptif dari train_por.
"""

train_por.describe()

"""Secara angka, value dalam tiap kolom di train_por tidak terlalu besar perbedaan range data dan perbedaanya. Namun agar lebih optimal, kita lakukan normalisasi"""

# Mmebuat Normalization Layer
normalizer = preprocessing.Normalization(axis=-1)
normalizer.adapt(np.array(train_features))          # adapt into the data
print(normalizer.mean.numpy())

"""# Model 1. Linear Regression (single input: absences)

> Mencoba memprediksi nilai Walc (weelky alcohol consumption dari absences (jumlah absensi)


"""

# Normalize variabel input (absences)
absences = np.array(train_features['absences'])
absences_normalizer = preprocessing.Normalization(input_shape=[1,], axis=None)
absences_normalizer.adapt(absences)

# Membuat sequential model
absences_model = tf.keras.Sequential([
    absences_normalizer,
    layers.Dense(units=1)])
absences_model.summary()

absences_model.predict(absences[:10])

absences_model.compile(
    optimizer=tf.optimizers.Adam(learning_rate=0.1),
    loss='mean_absolute_error')

"""Menjalankan model training:"""

# Commented out IPython magic to ensure Python compatibility.
# # Execute the training
# %%time
# history_reg = absences_model.fit(
#     train_features['absences'], train_labels_Walc,
#     epochs=200,
#     # suppress logging
#     verbose=0,
#     # Calculate validation results on 20% of the training data
#     validation_split = 0.2)
#

# Membuat fungsi untuk menggambar plot
def plot_loss(history_reg):
  plt.plot(history_reg.history['loss'], label='loss')
  plt.plot(history_reg.history['val_loss'], label='val_loss')
  plt.ylim([1, 1.1])
  plt.xlabel('Epoch')
  plt.ylabel('Error Walc')
  plt.legend()
  plt.grid(True)

# Memanggil fungsi plot_loss untuk memunculkan plot
plot_loss(history_reg)

"""Hasil training dengan 200 epoch memperlihatkan error Walc yang semakin smooth tiap epoch nya. Error nilai Walc yang terjadi sekitar 0.4.

Selanjutnya kita akan mencoba melakukan prediksi dengan kencenderungan jumlah konsumsi alkohol perminggu (Walc) dari faktor absensi (absences). Agar lebih mudah dimengerti, proses prediksi akan kita gambarkan dengan grafik.
"""

# Define x & y axis and limits
x = tf.linspace(0.0, 35, 36)
y = absences_model.predict(x)

def plot_absences_reg(x, y):
  plt.scatter(train_features['absences'], train_labels_Walc, label='Data')
  plt.plot(x, y, color='k', label='Predictions')
  plt.xlabel('absences')
  plt.ylabel('Walc')
  plt.legend()

# Draw The Plot
plot_absences_reg(x,y)

"""Terlihat dari grafik, hasil prediksi dengan menggunakan model regresi 1 variabel input (absences) di atas belum terlalu bagus. Hal ini mungkin terjadi karena masih ada outlier dalam data kita, terutama ada 1 data yang value absences nya mencapai 30.

Save test_result untuk evaluasi.
"""

test_results = {}

test_results['absences_model'] = absences_model.evaluate(
    test_features['absences'],
    test_labels_Walc, verbose=0)

"""# Model 2: Linear Regression (multiple input)

Pada model kali ini, kita akan memprediksi nilai Walc dengan menggunakan semua variabel, tidak hanya *absences*. Namun masih memakai metode linear regression.
"""

# Melakukan normalization ke seluruh dataset
linear_model = tf.keras.Sequential([
    normalizer,
    layers.Dense(units=1)
])

linear_model.predict(train_features[:10])

# Rumus sederhana persamaan linear: y = mx + b
# Mencari koefisien m ke seluruh variable (total 58 variabel)

linear_model.layers[1].kernel

#compile the model

linear_model.compile(
    optimizer=tf.optimizers.Adam(learning_rate=0.1),
    loss='mean_absolute_error')

# Commented out IPython magic to ensure Python compatibility.
# # Train the model
# 
# %%time
# history_linear_model = linear_model.fit(
#     train_features, train_labels_Walc, 
#     epochs=200,
#     # suppress logging
#     verbose=0,
#     # Calculate validation results on 20% of the training data
#     validation_split = 0.2)

def plot_loss_linear_model(history):
  plt.plot(history_linear_model.history['loss'], label='loss')
  plt.plot(history_linear_model.history['val_loss'], label='val_loss')
  plt.ylim([0.5, 2.25])
  plt.xlabel('Epoch')
  plt.ylabel('Error [Walc]')
  plt.legend()
  plt.grid(True)

# menggambar plot
plot_loss_linear_model(history_linear_model)

"""Mencoba memprediksi nilai Walc dengan menggunakan linear model yang baru saja dibuat:"""

test_predictions_linear_model = linear_model.predict(test_features).flatten()

a = plt.axes(aspect='equal')
plt.scatter(test_labels_Walc, test_predictions_linear_model)
plt.xlabel('True Values [Walc]')
plt.ylabel('Predictions [Walc]')
limsy = [0, 6]
limsx = [0, 6]
plt.xlim(limsx)
plt.ylim(limsy)
_ = plt.plot(limsx, limsy)

error = test_predictions_linear_model - test_labels_Walc
plt.hist(error, bins=400)
plt.xlabel('Prediction Error [Walc]')
_ = plt.ylabel('Count')

Dari 2 grafik di atas, terlihat hasil prediction vs true values yang masih berbeda-beda (scattered dan tidak mendekati garis diagonal). Perbedaan prediction errornya sampai ± 3.

"""Save test_result untuk evaluasi di akhir"""

test_results['linear_model'] = linear_model.evaluate(
    test_features, test_labels_Walc, verbose=0)

"""# Model 3: DNN (single input: absences)


Masih ingin memprediksikan pengaruh variabel *absences* terhadap *Walc*, namun kali ini kita menggunakan metode Deep Neural Network (DNN)


"""

# Membuat build_and_compile function
def build_and_compile_model(norm):
  model = keras.Sequential([
      norm,
      layers.Dense(64, activation='relu'),
      layers.Dense(64, activation='relu'),
      layers.Dense(1)
  ])

# Compile
  model.compile(loss='mean_absolute_error',
                optimizer=tf.keras.optimizers.Adam(0.001))
  return model

# Membuat model untuk single input (absences)
dnn_absences_model = build_and_compile_model(absences_normalizer)

dnn_absences_model.summary()

"""Lalu train modelnya sambil divisualisasikan progressnya."""

# Commented out IPython magic to ensure Python compatibility.
# # Train the model
# %%time
# history_dnn1 = dnn_absences_model.fit(
#     train_features['absences'], train_labels_Walc,
#     validation_split=0.2,
#     verbose=0, epochs=200)

def plot_loss(history_dnn1):
  plt.plot(history_dnn1.history['loss'], label='loss')
  plt.plot(history_dnn1.history['val_loss'], label='val_loss')
  plt.ylim([1, 1.1])
  plt.xlabel('Epoch')
  plt.ylabel('Error [Walc]')
  plt.legend()
  plt.grid(True)

# Memanggil fungsi plot_loss untuk memunculkan plot
plot_loss(history_dnn1)

"""Dibanding dengan model linear regression yang dibuat sebelumnya, error nya jauh lebih kecil (sekitar 0.2-0.3)"""

x = tf.linspace(0.0, 35, 36)
y = dnn_absences_model.predict(x)

def plot_absences_dnn1(x, y):
  plt.scatter(train_features['absences'], train_labels_Walc, label='Data')
  plt.plot(x, y, color='k', label='Predictions')
  plt.xlabel('absences')
  plt.ylabel('Walc')
  plt.legend()

plot_absences_dnn1(x,y)

"""Untuk absences 0-5, prediksinya sudah tepat. Namun selebihnya belum dapat dideprediksi dengan akurat

Save test_result untuk evaluasi di akhir
"""

test_results['dnn_absences_model'] = dnn_absences_model.evaluate(
    test_features['absences'], test_labels_Walc,
    verbose=0)

"""# Model 4: DNN (multiple input)"""

dnn_model = build_and_compile_model(normalizer)
dnn_model.summary()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# history_dnn2 = dnn_model.fit(
#     train_features, train_labels_Walc,
#     validation_split=0.2,
#     verbose=0, epochs=200)

def plot_loss_dnn2(history_dnn2):
  plt.plot(history_dnn2.history['loss'], label='loss')
  plt.plot(history_dnn2.history['val_loss'], label='val_loss')
  plt.ylim([0, 2])
  plt.xlabel('Epoch')
  plt.ylabel('Error Walc')
  plt.legend()
  plt.grid(True)

plot_loss_dnn2(history_dnn2)

test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels_Walc, verbose=0)

Kita coba memprediksi Walc dari seluruh variabel dengan menggunakan DNN multiple input

test_predictions_dnn_model = dnn_model.predict(test_features).flatten()

a = plt.axes(aspect='equal')
plt.scatter(test_labels_Walc, test_predictions_dnn_model)
plt.xlabel('True Values [Walc]')
plt.ylabel('Predictions [Walc]')
limsy = [0, 6]
limsx = [0, 6]
plt.xlim(limsx)
plt.ylim(limsy)
_ = plt.plot(limsx, limsy)

error = test_predictions_dnn_model - test_labels_Walc
plt.hist(error, bins=400)
plt.xlabel('Prediction Error [Walc]')
_ = plt.ylabel('Count')

"""Hasil prediksi dengan menggunakan model DNN (multiple input) bisa dibilang cukup bagus, dengan maksimal error ± 0.15

Save test_result untuk evaluasi di akhir
"""

test_results['dnn_model'] = dnn_model.evaluate(
    test_features, test_labels_Walc,
    verbose=0)

"""# Conclusion"""

pd.DataFrame(test_results, index=['Mean absolute error [Walc]']).T

Dari ketiga model yang telah kita buat, DNN multiple input (dnn_model) memiliki mean absolute error paling kecil, yang artinya paling akurat dalam memprediksi Walc.